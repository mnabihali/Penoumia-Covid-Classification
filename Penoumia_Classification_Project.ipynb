{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqcFkGViysWn"
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D\n",
        "from keras.layers import Activation, Dropout, BatchNormalization, Flatten, Dense, AvgPool2D,MaxPool2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iThrzr8p2jYa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7b1eb52-c3e7-46eb-dd7e-e8addeca6bc0"
      },
      "source": [
        "dataset_dir_train = '/content/drive/My Drive/Penoumia/train'\n",
        "dataset_dir_test = '/content/drive/My Drive/Penoumia/test'\n",
        "dataset_dir_val = '/content/drive/My Drive/Penoumia/val'\n",
        "os.listdir(dataset_dir_train)\n",
        "os.listdir(dataset_dir_test)\n",
        "os.listdir(dataset_dir_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NORMAL', 'PNEUMONIA']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA1PRhcc4A6z"
      },
      "source": [
        "normal_image_train = []\n",
        "for im_path in glob.glob(dataset_dir_train + '/NORMAL/*'):\n",
        "  normal_image_train.append(mpimg.imread(im_path))\n",
        "print (len(normal_image_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_E9DRcxCNhY"
      },
      "source": [
        "covid_image_train = []\n",
        "for im_path in glob.glob(dataset_dir_train + '/PNEUMONIA/*'):\n",
        "  covid_image_train.append(mpimg.imread(im_path))\n",
        "print(len(covid_image_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j94oPerM8s9D"
      },
      "source": [
        "normal_image_test = []\n",
        "for im_path in glob.glob(dataset_dir_test + '/NORMAL/*'):\n",
        "  normal_image_test.append(mpimg.imread(im_path))\n",
        "print (len(normal_image_test))\n",
        "covid_image_test = []\n",
        "for im_path in glob.glob(dataset_dir_test+ '/PNEUMONIA/*'):\n",
        "  covid_image_test.append(mpimg.imread(im_path))\n",
        "print(len(covid_image_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8k8qY529SCj"
      },
      "source": [
        "fig_norm = plt.figure()\n",
        "fig_norm.suptitle('Normal')\n",
        "plt.imshow(normal_image_train[0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvya7I2q9yjr"
      },
      "source": [
        "fig_cov = plt.figure()\n",
        "fig_cov.suptitle('Covid')\n",
        "plt.imshow(covid_image_train[0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jHA2DVB-UNL"
      },
      "source": [
        "img_he = 150\n",
        "img_wi = 150\n",
        "n_channels = 3\n",
        "\n",
        "INPUT_SHAPE = (img_he, img_wi, n_channels)\n",
        "num_classes = 2  # Binary classification\n",
        "no_epoches = 150\n",
        "batch_size = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maOS8A5y-X-h"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3,3), input_shape =INPUT_SHAPE))\n",
        "model.add(Activation ('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3,3)))\n",
        "model.add(Activation ('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(250, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(64, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(256, (2,2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-IRisNp-th2"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuD6f3mS_IWD"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, \n",
        "                                   zoom_range=0.2, horizontal_flip=True, validation_split=0.3)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(dataset_dir_train, target_size=(img_he, img_wi), \n",
        "                                                    batch_size=batch_size, class_mode='binary', subset='training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkJoHCoC_JzE"
      },
      "source": [
        "validation_generator = train_datagen.flow_from_directory(dataset_dir_test, target_size=(img_he, img_wi),\n",
        "                                                         batch_size=batch_size, class_mode='binary'\n",
        "                                                         , shuffle = False, subset='validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3i8nEOZ_Yen"
      },
      "source": [
        "history = model.fit(train_generator, steps_per_epoch = train_generator.samples//batch_size, \n",
        "                              validation_data = validation_generator,\n",
        "                              validation_steps = validation_generator.samples //batch_size, epochs = no_epoches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE5AcUXc3v3z"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiFoXQpZORpR"
      },
      "source": [
        "from keras import applications\n",
        "from keras import optimizers\n",
        "# ResNet50 with pre-trained weights\n",
        "base_model = applications.ResNet50(weights='imagenet', include_top=False)\n",
        "train_after_layer = 25  \n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "# Add your top layer block\n",
        "model2 = Model(base_model.input, predictions)\n",
        "\n",
        "# set the first K layers (up to the last conv block)\n",
        "# to non-trainable (weights will not change during training)\n",
        "for layer in model2.layers[:train_after_layer]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model2.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, \n",
        "                                   zoom_range=0.2, horizontal_flip=True, validation_split=0.3)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(dataset_dir, target_size=(img_he, img_wi), \n",
        "                                                    batch_size=batch_size, class_mode='binary', subset='training')\n",
        "validation_generator = train_datagen.flow_from_directory(dataset_dir, target_size=(img_he, img_wi),\n",
        "                                                         batch_size=batch_size, class_mode='binary'\n",
        "                                                         , shuffle = False, subset='validation')\n",
        "epochs_fine = 100\n",
        "\n",
        "model2.fit_generator(train_generator, steps_per_epoch = train_generator.samples//batch_size, \n",
        "                              validation_data = validation_generator,\n",
        "                              validation_steps = validation_generator.samples //batch_size, epochs = epochs_fine)\n",
        "\n",
        "model2.save_weights('finetuned.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuVoaFZ9anO2"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}